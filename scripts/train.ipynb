{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOgxqOX3XbiI",
        "outputId": "ee248a9e-3063-424c-838d-1bf31e6f27d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 26 06:15:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0              41W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZZZf6bxXjb6"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ncVE4CjXkfg"
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install transformers torch\n",
        "!pip install datasets\n",
        "!pip install tqdm\n",
        "!pip install wandb\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv1YqOORXmVo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2InPjhD8dxI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "WARMUP_RATIO = 0.06\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 3e-5\n",
        "FP16 = False  # False - I'm considering CPU inference later\n",
        "LOGGING_STEPS = 10\n",
        "OPTIM = \"adamw_torch\"\n",
        "EVALUATION_STRATEGY = 'steps'\n",
        "SAVE_STRATEGY = \"steps\"\n",
        "EVAL_STEPS = 400\n",
        "MAX_GRAD_NORM = 1.0\n",
        "SAVE_STEPS = 4000\n",
        "LR_SCHEDULER_TYPE = 'cosine'\n",
        "OUTPUT_DIR = './nllb_350M'\n",
        "LOAD_BEST_MODEL_AT_END=False\n",
        "SAVE_TOTAL_LIMIT=1\n",
        "DDP_FIND_UNUSED_PARAMETERS=False\n",
        "GROUP_BY_LENGTH=False\n",
        "REPORT_TO='wandb'\n",
        "\n",
        "TEMPERATURE = 5\n",
        "LAMBDA_PARAM = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPqJv6iyS-hC"
      },
      "outputs": [],
      "source": [
        "# teacher_model = AutoModelForSeq2SeqLM.from_pretrained('facebook/nllb-200-3.3B')\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('facebook/nllb-200-distilled-600M')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('facebook/nllb-200-distilled-600M', src_lang='en_Latn', tgt_lang='kor_Hang')\n",
        "\n",
        "# model.model.encoder.layers = model.model.encoder.layers[:3]\n",
        "# model.model.decoder.layers = model.model.decoder.layers[:3]\n",
        "\n",
        "# model.config.encoder_layers = 3\n",
        "# model.config.decoder_layers = 3\n",
        "\n",
        "# model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdPH9LFVWyvf"
      },
      "outputs": [],
      "source": [
        "teacher_model = AutoModelForSeq2SeqLM.from_pretrained('facebook/nllb-200-1.3B')\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('dhtocks/nllb_350M_en_ko_v16')\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/nllb-200-distilled-600M', src_lang='eng_Latn', tgt_lang='kor_Hang')\n",
        "\n",
        "teacher_model.config.forced_bos_token_id=256098\n",
        "model.config.forced_bos_token_id=256098\n",
        "\n",
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh0zC6lMNWXH"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96y1Du9_NZpQ"
      },
      "outputs": [],
      "source": [
        "teacher_model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH8r89nOSq6r"
      },
      "outputs": [],
      "source": [
        "def data_prepare(dataset):\n",
        "  return tokenizer(dataset['data']['eng_Latn'] , text_target=dataset['data']['kor_Hang'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT1wJcBeYLpJ"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset('dhtocks/nllb_en_ko_1M_part14')\n",
        "\n",
        "en_dataset = load_dataset(\"facebook/flores\", 'eng_Latn')\n",
        "ko_dataset = load_dataset(\"facebook/flores\", 'kor_Hang')\n",
        "\n",
        "en_dataset = en_dataset['dev']['sentence']\n",
        "ko_dataset = ko_dataset['dev']['sentence']\n",
        "\n",
        "eval_dataset = {'data': []}\n",
        "\n",
        "for i in range(len(en_dataset)):\n",
        "  eval_dataset['data'].append({'eng_Latn': en_dataset[i], 'kor_Hang': ko_dataset[i]})\n",
        "\n",
        "train_dataset = Dataset.from_dict({'data': train_dataset['train']['data']})\n",
        "eval_dataset = Dataset.from_dict(eval_dataset)\n",
        "\n",
        "\n",
        "# Required Data Format\n",
        "#\n",
        "# 'train': {\n",
        "#     'data': [\n",
        "#         {\n",
        "#             'eng_Latn': 'good morning',\n",
        "#             'kor_Hang': '좋은 아침'\n",
        "#         },\n",
        "#         ...\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "train_dataset = train_dataset.map(data_prepare, remove_columns=train_dataset.column_names)\n",
        "eval_dataset = eval_dataset.map(data_prepare, remove_columns=eval_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJFxW50QF6El"
      },
      "outputs": [],
      "source": [
        "class DistilTrainer(Seq2SeqTrainer):\n",
        "    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):\n",
        "        super().__init__(model=student_model, *args, **kwargs)\n",
        "        self.teacher = teacher_model\n",
        "        self.student = student_model\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.teacher.to(device)\n",
        "        self.teacher.eval()\n",
        "        self.temperature = temperature\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "    def compute_loss(self, student, inputs, return_outputs=False):\n",
        "        student_output = self.student(**inputs)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          teacher_output = self.teacher(**inputs)\n",
        "\n",
        "        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n",
        "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
        "\n",
        "        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n",
        "\n",
        "        student_target_loss = student_output.loss\n",
        "\n",
        "        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n",
        "        return (loss, student_output) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w9NnV-_IDBxq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"NLLB_DSTILLATION\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"nllb_350M\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=FP16, # False - I'm considering CPU inference later\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    optim=OPTIM,\n",
        "    evaluation_strategy=EVALUATION_STRATEGY,\n",
        "    eval_steps=EVAL_STEPS,\n",
        "    save_strategy=SAVE_STRATEGY,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    save_steps=SAVE_STEPS,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
        "    save_total_limit=SAVE_TOTAL_LIMIT,\n",
        "    ddp_find_unused_parameters=DDP_FIND_UNUSED_PARAMETERS,\n",
        "    group_by_length=GROUP_BY_LENGTH,\n",
        "    report_to=REPORT_TO\n",
        ")\n",
        "\n",
        "trainer = DistilTrainer(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=model,\n",
        "    temperature=TEMPERATURE,\n",
        "    lambda_param=LAMBDA_PARAM,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=DataCollatorForSeq2Seq(\n",
        "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
        "    ),\n",
        ")\n",
        "\n",
        "teacher_model = torch.compile(teacher_model)\n",
        "model = torch.compile(model)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.push_to_hub('dhtocks/nllb_350M_en_ko_v17', private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M27gx-L0GZS2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}